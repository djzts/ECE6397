{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of DCGAN_test_256.ipynb","provenance":[{"file_id":"18GQWru9P7GRG-_EZGiqnpMJ03q91ec3q","timestamp":1607246743831}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"18GQWru9P7GRG-_EZGiqnpMJ03q91ec3q","authorship_tag":"ABX9TyM0sN2mPcQPix6VQib4YqH0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3cd21ca1094a4090bf8f4051fbb23af8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a34d858b14ca4ef3a613d7cab2475dd3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2cc88b6f1c5e4e2f9488b39cff56d09d","IPY_MODEL_0de6ee426b8d43ab8974c0b84ffa07f3"]}},"a34d858b14ca4ef3a613d7cab2475dd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2cc88b6f1c5e4e2f9488b39cff56d09d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5e7a16ad3b98421eb2ed1a05e82422ff","_dom_classes":[],"description":" 26%","_model_name":"FloatProgressModel","bar_style":"","max":10000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2641,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aab3e03f75b54f3bbff3194b67c3749d"}},"0de6ee426b8d43ab8974c0b84ffa07f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5249bb0679c54c86b32a120b49bb0047","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2641/10000 [10:45:35&lt;31:19:30, 15.32s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f3d1507373b4340b5e9538e7e1c9283"}},"5e7a16ad3b98421eb2ed1a05e82422ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aab3e03f75b54f3bbff3194b67c3749d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5249bb0679c54c86b32a120b49bb0047":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0f3d1507373b4340b5e9538e7e1c9283":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"DzAYbVIjqRGF"},"source":[" from __future__ import print_function, division\n","\n","#from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, AveragePooling2D, GaussianNoise\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D,Conv2DTranspose\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","from tqdm import notebook\n","import os\n","import sys\n","import numpy as np\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3qUrSevEzq0r"},"source":[""]},{"cell_type":"code","metadata":{"id":"qCUxINYu3WOn"},"source":["def load_data():\n","  data_x_p1 = np.load(\"/content/drive/MyDrive/UHCourse/ECE6397/mldata_256/Data_x_Bacteria.npy\")\n","  #data_x_p2 = np.load(\"/content/drive/MyDrive/UHCourse/ECE6397/mldata/Data_x_Normal.npy\")\n","  #data_x_p3 = np.load(\"/content/drive/MyDrive/UHCourse/ECE6397/mldata/Data_x_Virus.npy\")\n","  #data_x_p4 = np.load(\"/content/drive/MyDrive/UHCourse/ECE6397/mldata/Data_x_Covid.npy\")\n","  #X_Train = np.concatenate((data_x_p1,data_x_p2,data_x_p3,data_x_p4),axis = 0)\n","\n","  data_y_p1 = np.load(\"/content/drive/MyDrive/UHCourse/ECE6397/mldata_256/Data_y_Bacteria.npy\")\n","  #data_y_p2 = np.load(\"/content/drive/MyDrive/UHCourse/ECE6397/mldata/Data_y_Normal.npy\")\n","  #data_y_p3 = np.load(\"/content/drive/MyDrive/UHCourse/ECE6397/mldata/Data_y_Virus.npy\")\n","  #data_y_p4 = np.load(\"/content/drive/MyDrive/UHCourse/ECE6397/mldata/Data_y_Covid.npy\")\n","  #y_Train = np.concatenate((data_y_p1,data_y_p2,data_y_p3,data_y_p4),axis = 0)\n","\n","  #return X_Train, y_Train\n","  #X_mean = np.mean(data_x_p1,axis=-1)\n","  X_0 = data_x_p1[:,:,:,0]\n","\n","  return X_0, data_y_p1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7eaI9Rz2BgQ"},"source":["class DCGAN():\n","    def __init__(self):\n","        # Input shape\n","        self.img_rows =   256 #@param  # 图像的高\n","        self.img_cols =   256 #@param  # 图像的宽\n","        self.channels =     1 #@param  # 彩色图像\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","        self.latent_dim = 4096  #@param\n","        self.init_shape =   64 #@param  # gen\n","\n","\n","        # 设置学习率为0.0002\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='binary_crossentropy',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # The generator takes noise as input and generates imgs\n","        z = Input(shape=(self.init_shape,))\n","        img = self.generator(z)\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # The discriminator takes generated images as input and determines validity\n","        valid = self.discriminator(img)\n","\n","        # The combined model  (stacked generator and discriminator)\n","        # Trains the generator to fool the discriminator\n","        self.combined = Model(z, valid)\n","        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n","    def build_generator(self):\n","        kernel_size_G = [4,4,4,3,3,3,3,3] #@param\n","        _momentum_G = 0.7 #@param\n","        model = Sequential()\n","\n","        model.add(Dense(self.latent_dim, activation=\"relu\", input_dim=self.init_shape))\n","        \n","        #1x1x4096 \n","        model.add(Reshape(target_shape=[1,1,self.latent_dim]))\n","        model.add(Conv2DTranspose(filters = 256, kernel_size = kernel_size_G[0]))\n","        model.add(Activation('relu'))\n","\n","\n","        #4x4x256 - kernel sized increased by 1\n","        model.add(Conv2D(256, kernel_size=kernel_size_G[1], padding=\"same\"))\n","        model.add(BatchNormalization(momentum=_momentum_G))\n","        model.add(Activation(\"relu\"))\n","        model.add(UpSampling2D())\n","        \n","        #8x8x256 - kernel sized increased by 1\n","        model.add(Conv2D(128, kernel_size=kernel_size_G[2], padding=\"same\"))\n","        model.add(BatchNormalization(momentum=_momentum_G))\n","        model.add(Activation(\"relu\"))\n","        model.add(UpSampling2D())\n","\n","        #16x16x128\n","        model.add(Conv2D(64, kernel_size=kernel_size_G[3], padding=\"same\"))\n","        model.add(BatchNormalization(momentum=_momentum_G))\n","        model.add(Activation(\"relu\"))\n","        model.add(UpSampling2D())\n","        \n","        #32x32x64\n","        model.add(Conv2D(32, kernel_size=kernel_size_G[4], padding=\"same\"))\n","        model.add(BatchNormalization(momentum=_momentum_G))\n","        model.add(Activation(\"relu\"))\n","        model.add(UpSampling2D())\n","        \n","        #64x64x32\n","        model.add(Conv2D(32, kernel_size=kernel_size_G[4], padding=\"same\"))\n","        model.add(BatchNormalization(momentum=_momentum_G))\n","        model.add(Activation(\"relu\"))\n","        model.add(UpSampling2D())\n","\n","        #128x128x16\n","        model.add(Conv2D(32, kernel_size=kernel_size_G[5], padding=\"same\"))\n","        model.add(BatchNormalization(momentum=_momentum_G))\n","        model.add(Activation(\"relu\"))\n","        model.add(UpSampling2D())\n","\n","\n","        #256x256x8\n","        model.add(Conv2D(self.channels, kernel_size=kernel_size_G[6], padding=\"same\"))\n","        model.add(Activation(\"tanh\"))\n","\n","        model.summary()\n","\n","        noise = Input(shape=(self.init_shape,))\n","        img = model(noise)\n","\n","        return Model(noise, img)\n","    def build_discriminator(self):\n","        filter_num = [8,16,32,64,128,256] #@param\n","        Kernel_size = [3,3,3,3,3,3] #@param\n","        Stride = [1,1,1,1,1,1] #@param\n","        dropout = 0.25 #@param\n","        _momentum = 0.7 #@param\n","        _alpha = 0.2 #@param\n","        model = Sequential()\n","\n","        #0 #256x256x3 Image\n","        model.add(Conv2D(filter_num[0], kernel_size = Kernel_size[0], strides = Stride[0], input_shape=self.img_shape, padding=\"same\"))\n","        model.add(LeakyReLU(alpha=_alpha))\n","        model.add(Dropout(dropout))\n","        model.add(AveragePooling2D())\n","        \n","        #1  #128x128x8\n","        model.add(Conv2D(filter_num[1], kernel_size= Kernel_size[1], strides = Stride[1], padding=\"same\"))\n","        #model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n","        model.add(BatchNormalization(momentum=_momentum))\n","        model.add(LeakyReLU(alpha=_alpha))\n","        model.add(Dropout(dropout))\n","        model.add(AveragePooling2D())\n","        \n","        #2 #64x64x16\n","        model.add(Conv2D(filter_num[2], kernel_size= Kernel_size[2], strides = Stride[2], padding=\"same\"))\n","        model.add(BatchNormalization(momentum=_momentum))\n","        model.add(LeakyReLU(alpha=_alpha))\n","        model.add(Dropout(dropout))\n","        model.add(AveragePooling2D())\n","        \n","        #3 32x32x32\n","        model.add(Conv2D(filter_num[3], kernel_size=Kernel_size[3], strides= Stride[3], padding=\"same\"))\n","        model.add(BatchNormalization(momentum=_momentum))\n","        model.add(LeakyReLU(alpha=_alpha))\n","        model.add(Dropout(dropout))     \n","        model.add(AveragePooling2D())\n","        \n","        #4 #16x16x64\n","        model.add(Conv2D(filter_num[4], kernel_size=Kernel_size[4], strides= Stride[4], padding=\"same\"))\n","        model.add(BatchNormalization(momentum=_momentum))\n","        model.add(LeakyReLU(alpha=_alpha))\n","        model.add(Dropout(dropout))      \n","        model.add(AveragePooling2D())\n","        \n","        #5 #8x8x128\n","        model.add(Conv2D(filter_num[5], kernel_size=Kernel_size[5], strides= Stride[5], padding=\"same\"))\n","        model.add(BatchNormalization(momentum=_momentum))\n","        model.add(LeakyReLU(alpha=_alpha))\n","        model.add(Dropout(dropout))\n","        model.add(AveragePooling2D())\n","\n","        #6 #4x4x256\n","        model.add(Flatten())\n","\n","        #7 #256\n","        model.add(Dense(256))\n","        model.add(LeakyReLU(alpha=_alpha))       \n","        \n","        \n","        model.add(Dense(1, activation='sigmoid'))\n","        model.summary()\n","        img = Input(shape=self.img_shape)\n","        validity = model(img)\n","        return Model(img, validity)\n","    def train(self, epochs, batch_size=128, save_interval=50):\n","        # Load the dataset\n","        X_train,y1 = load_data()\n","        X_train = np.expand_dims(X_train, axis=3)\n","        index = np.shape(X_train)[1]\n","        pic_path = '/content/drive/MyDrive/UHCourse/ECE6397/mlresult_%d/Bacteria_BS_'%index+str(batch_size)+'_SI'+str(save_interval)\n","        try:\n","          os.makedirs(pic_path)\n","        except:\n","          pass\n","        valid = np.ones((batch_size, 1))\n","        fake = np.zeros((batch_size, 1))\n","        for epoch in notebook.tqdm(range(epochs)):\n","            # ---------------------\n","            #  Train Discriminator\n","            # Select a random half of images\n","            idx = np.random.randint(0, X_train.shape[0], batch_size)\n","            imgs = X_train[idx]\n","            # Sample noise and generate a batch of new images\n","            noise = np.random.normal(0, 1, (batch_size, self.init_shape))\n","            gen_imgs = self.generator.predict(noise)\n","            # Train the discriminator (real classified as ones and generated as zeros)\n","            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n","            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","            # ---------------------\n","            #  Train Generator\n","            # ---------------------\n","            # Train the generator (wants discriminator to mistake images as real)\n","            g_loss = self.combined.train_on_batch(noise, valid)\n","            # Plot the progress\n","            # If at save interval => save generated image samples\n","            if epoch % save_interval == 0:\n","\n","                self.save_imgs(epoch,pic_path)\n","                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n","    def save_imgs(self, epoch,pic_path):\n","        r, c = 2, 2\n","        noise = np.random.normal(0, 1, (r * c, self.init_shape))\n","        gen_imgs = self.generator.predict(noise)\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","        np.save(pic_path+\"/img_%d.npy\" % epoch, gen_imgs)\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                plt\n","                #axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n","                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(pic_path+\"/img_%d.png\" % epoch)\n","        plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9-7L9aWzrzv","executionInfo":{"status":"ok","timestamp":1607152720933,"user_tz":360,"elapsed":1547,"user":{"displayName":"Zhongqi Zhao","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg6I_VWV5b7NlsHTRF7MJBaZRT1IHUzATnXNOchmQ=s64","userId":"11751221736501973963"}},"outputId":"7539100d-10bd-41e1-c4cc-0af44c5cdac5"},"source":["#if __name__ == '__main__':\n","dcgan = DCGAN()\n","#  dcgan.train(epochs=10000, batch_size=50, save_interval=50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_39 (Conv2D)           (None, 256, 256, 8)       80        \n","_________________________________________________________________\n","leaky_re_lu_21 (LeakyReLU)   (None, 256, 256, 8)       0         \n","_________________________________________________________________\n","dropout_18 (Dropout)         (None, 256, 256, 8)       0         \n","_________________________________________________________________\n","average_pooling2d_18 (Averag (None, 128, 128, 8)       0         \n","_________________________________________________________________\n","conv2d_40 (Conv2D)           (None, 128, 128, 16)      1168      \n","_________________________________________________________________\n","batch_normalization_33 (Batc (None, 128, 128, 16)      64        \n","_________________________________________________________________\n","leaky_re_lu_22 (LeakyReLU)   (None, 128, 128, 16)      0         \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 128, 128, 16)      0         \n","_________________________________________________________________\n","average_pooling2d_19 (Averag (None, 64, 64, 16)        0         \n","_________________________________________________________________\n","conv2d_41 (Conv2D)           (None, 64, 64, 32)        4640      \n","_________________________________________________________________\n","batch_normalization_34 (Batc (None, 64, 64, 32)        128       \n","_________________________________________________________________\n","leaky_re_lu_23 (LeakyReLU)   (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","dropout_20 (Dropout)         (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","average_pooling2d_20 (Averag (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_42 (Conv2D)           (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_35 (Batc (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_24 (LeakyReLU)   (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","dropout_21 (Dropout)         (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","average_pooling2d_21 (Averag (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_43 (Conv2D)           (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","batch_normalization_36 (Batc (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)   (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","dropout_22 (Dropout)         (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","average_pooling2d_22 (Averag (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_44 (Conv2D)           (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","batch_normalization_37 (Batc (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)   (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","dropout_23 (Dropout)         (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","average_pooling2d_23 (Averag (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 4096)              0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 256)               1048832   \n","_________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)   (None, 256)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 1,444,481\n","Trainable params: 1,443,489\n","Non-trainable params: 992\n","_________________________________________________________________\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_11 (Dense)             (None, 4096)              266240    \n","_________________________________________________________________\n","reshape_3 (Reshape)          (None, 1, 1, 4096)        0         \n","_________________________________________________________________\n","conv2d_transpose_3 (Conv2DTr (None, 4, 4, 256)         16777472  \n","_________________________________________________________________\n","activation_24 (Activation)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv2d_45 (Conv2D)           (None, 4, 4, 256)         1048832   \n","_________________________________________________________________\n","batch_normalization_38 (Batc (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","activation_25 (Activation)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","up_sampling2d_18 (UpSampling (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","conv2d_46 (Conv2D)           (None, 8, 8, 128)         524416    \n","_________________________________________________________________\n","batch_normalization_39 (Batc (None, 8, 8, 128)         512       \n","_________________________________________________________________\n","activation_26 (Activation)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","up_sampling2d_19 (UpSampling (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_47 (Conv2D)           (None, 16, 16, 64)        73792     \n","_________________________________________________________________\n","batch_normalization_40 (Batc (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","activation_27 (Activation)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","up_sampling2d_20 (UpSampling (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_48 (Conv2D)           (None, 32, 32, 32)        18464     \n","_________________________________________________________________\n","batch_normalization_41 (Batc (None, 32, 32, 32)        128       \n","_________________________________________________________________\n","activation_28 (Activation)   (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","up_sampling2d_21 (UpSampling (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","conv2d_49 (Conv2D)           (None, 64, 64, 32)        9248      \n","_________________________________________________________________\n","batch_normalization_42 (Batc (None, 64, 64, 32)        128       \n","_________________________________________________________________\n","activation_29 (Activation)   (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","up_sampling2d_22 (UpSampling (None, 128, 128, 32)      0         \n","_________________________________________________________________\n","conv2d_50 (Conv2D)           (None, 128, 128, 32)      9248      \n","_________________________________________________________________\n","batch_normalization_43 (Batc (None, 128, 128, 32)      128       \n","_________________________________________________________________\n","activation_30 (Activation)   (None, 128, 128, 32)      0         \n","_________________________________________________________________\n","up_sampling2d_23 (UpSampling (None, 256, 256, 32)      0         \n","_________________________________________________________________\n","conv2d_51 (Conv2D)           (None, 256, 256, 1)       289       \n","_________________________________________________________________\n","activation_31 (Activation)   (None, 256, 256, 1)       0         \n","=================================================================\n","Total params: 18,730,177\n","Trainable params: 18,729,089\n","Non-trainable params: 1,088\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":848,"referenced_widgets":["3cd21ca1094a4090bf8f4051fbb23af8","a34d858b14ca4ef3a613d7cab2475dd3","2cc88b6f1c5e4e2f9488b39cff56d09d","0de6ee426b8d43ab8974c0b84ffa07f3","5e7a16ad3b98421eb2ed1a05e82422ff","aab3e03f75b54f3bbff3194b67c3749d","5249bb0679c54c86b32a120b49bb0047","0f3d1507373b4340b5e9538e7e1c9283"]},"id":"ehqVvLZc6iOR","outputId":"545978e3-e946-4c31-fc0e-465d6e14b06d"},"source":["\n","dcgan.train(epochs=10000, batch_size=80, save_interval=60)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cd21ca1094a4090bf8f4051fbb23af8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["0 [D loss: 1.641784, acc.: 35.62%] [G loss: 0.625675]\n","60 [D loss: 0.004670, acc.: 100.00%] [G loss: 0.055915]\n","120 [D loss: 0.000441, acc.: 100.00%] [G loss: 0.079373]\n","180 [D loss: 0.000675, acc.: 100.00%] [G loss: 0.122547]\n","240 [D loss: 0.000380, acc.: 100.00%] [G loss: 0.019982]\n","300 [D loss: 0.000238, acc.: 100.00%] [G loss: 0.048033]\n","360 [D loss: 0.000208, acc.: 100.00%] [G loss: 0.088415]\n","420 [D loss: 0.000099, acc.: 100.00%] [G loss: 0.000685]\n","480 [D loss: 0.000070, acc.: 100.00%] [G loss: 0.000711]\n","540 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.000730]\n","600 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.000791]\n","660 [D loss: 0.000081, acc.: 100.00%] [G loss: 0.000398]\n","720 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000896]\n","780 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.001646]\n","840 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001973]\n","900 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.002414]\n","960 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.001652]\n","1020 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.003783]\n","1080 [D loss: 0.000269, acc.: 100.00%] [G loss: 0.006053]\n","1140 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.008068]\n","1200 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.016315]\n","1260 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.004890]\n","1320 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.015600]\n","1380 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.033709]\n","1440 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.017427]\n","1500 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.011453]\n","1560 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.018936]\n","1620 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.029670]\n","1680 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.011239]\n","1740 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.013882]\n","1800 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.012106]\n","1860 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.506916]\n","1920 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.092614]\n","1980 [D loss: 0.000067, acc.: 100.00%] [G loss: 2.078569]\n","2040 [D loss: 0.058768, acc.: 98.75%] [G loss: 0.000705]\n","2100 [D loss: 0.001195, acc.: 100.00%] [G loss: 0.000027]\n","2160 [D loss: 0.000936, acc.: 100.00%] [G loss: 0.000004]\n","2220 [D loss: 0.000359, acc.: 100.00%] [G loss: 0.000008]\n","2280 [D loss: 0.000219, acc.: 100.00%] [G loss: 0.000005]\n","2340 [D loss: 0.000618, acc.: 100.00%] [G loss: 0.000008]\n","2400 [D loss: 0.000107, acc.: 100.00%] [G loss: 0.000005]\n","2460 [D loss: 0.000133, acc.: 100.00%] [G loss: 0.000006]\n","2520 [D loss: 0.000080, acc.: 100.00%] [G loss: 0.000004]\n","2580 [D loss: 0.000165, acc.: 100.00%] [G loss: 0.000003]\n","2640 [D loss: 0.000092, acc.: 100.00%] [G loss: 0.000003]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8Cly50GV0q4G"},"source":[""],"execution_count":null,"outputs":[]}]}